{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e995da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "745/745 [==============================] - 9s 8ms/step - loss: 102883.9297 - mse: 102883.9297 - mae: 232.6534 - val_loss: 76946.3828 - val_mse: 76946.3828 - val_mae: 225.0035\n",
      "Epoch 2/100\n",
      "745/745 [==============================] - 4s 6ms/step - loss: 78879.6406 - mse: 78879.6406 - mae: 228.4060 - val_loss: 75459.3672 - val_mse: 75459.3672 - val_mae: 223.9523\n",
      "Epoch 3/100\n",
      "745/745 [==============================] - 5s 6ms/step - loss: 78151.1719 - mse: 78151.1719 - mae: 226.4383 - val_loss: 74598.7578 - val_mse: 74598.7578 - val_mae: 221.6380\n",
      "Epoch 4/100\n",
      "745/745 [==============================] - 4s 6ms/step - loss: 76989.5078 - mse: 76989.5078 - mae: 224.3978 - val_loss: 73699.7188 - val_mse: 73699.7188 - val_mae: 219.7665\n",
      "Epoch 5/100\n",
      "745/745 [==============================] - 4s 6ms/step - loss: 76405.7812 - mse: 76405.7812 - mae: 222.2170 - val_loss: 73158.4688 - val_mse: 73158.4688 - val_mae: 217.6491\n",
      "Epoch 6/100\n",
      "745/745 [==============================] - 4s 6ms/step - loss: 75528.5312 - mse: 75528.5312 - mae: 220.5881 - val_loss: 72688.0391 - val_mse: 72688.0391 - val_mae: 215.6970\n",
      "Epoch 7/100\n",
      "745/745 [==============================] - 5s 6ms/step - loss: 75423.5078 - mse: 75423.5078 - mae: 219.7703 - val_loss: 72313.4609 - val_mse: 72313.4609 - val_mae: 214.5107\n",
      "Epoch 8/100\n",
      "745/745 [==============================] - 4s 6ms/step - loss: 75086.5078 - mse: 75086.5078 - mae: 218.5475 - val_loss: 71825.7500 - val_mse: 71825.7500 - val_mae: 214.2368\n",
      "Epoch 9/100\n",
      "745/745 [==============================] - 4s 6ms/step - loss: 74758.6953 - mse: 74758.6953 - mae: 217.4444 - val_loss: 71619.8984 - val_mse: 71619.8984 - val_mae: 213.4415\n",
      "Epoch 10/100\n",
      "745/745 [==============================] - 4s 6ms/step - loss: 74534.5625 - mse: 74534.5625 - mae: 217.4666 - val_loss: 71420.0781 - val_mse: 71420.0781 - val_mae: 212.7858\n",
      "Epoch 11/100\n",
      "745/745 [==============================] - 4s 6ms/step - loss: 74264.7344 - mse: 74264.7344 - mae: 216.6469 - val_loss: 71100.1406 - val_mse: 71100.1406 - val_mae: 212.9799\n",
      "Epoch 12/100\n",
      "745/745 [==============================] - 4s 6ms/step - loss: 74158.5859 - mse: 74158.5859 - mae: 216.5288 - val_loss: 70850.2109 - val_mse: 70850.2109 - val_mae: 212.4388\n",
      "Epoch 13/100\n",
      "745/745 [==============================] - 4s 6ms/step - loss: 73976.2812 - mse: 73976.2812 - mae: 215.7651 - val_loss: 70979.6406 - val_mse: 70979.6406 - val_mae: 211.7474\n",
      "Epoch 14/100\n",
      "745/745 [==============================] - 4s 6ms/step - loss: 73958.8906 - mse: 73958.8906 - mae: 216.1560 - val_loss: 70555.5547 - val_mse: 70555.5547 - val_mae: 210.7682\n",
      "Epoch 15/100\n",
      "328/745 [============>.................] - ETA: 2s - loss: 74340.4375 - mse: 74340.4375 - mae: 217.4139"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('Weather_data.csv')\n",
    "\n",
    "# Clean the data\n",
    "data = data.dropna()\n",
    "\n",
    "\n",
    "# Define input and output variables\n",
    "X = data[['temp', 'humidity', 'cloud_cover', 'wind_speed']]\n",
    "y = data['solar_radiation']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "# Standardize the input variables\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define the neural network model\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['mse', 'mae'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Make predictions\n",
    "new_X = np.array([[286.26,61,54.0,2.6]])\n",
    "prediction1 = model.predict(new_X)\n",
    "\n",
    "if prediction1<0:\n",
    "    prediction1=0\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data into Pandas DataFrame\n",
    "data2 = pd.read_csv('Separate_Power.csv')\n",
    "\n",
    "# Split the dataset into features and target variable\n",
    "X2 = data2[['Demand','Radiations']]\n",
    "y2 = data2[['Solar_Power','Grid_Power']]\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create decision tree regressor model\n",
    "model2 = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "# Train model on training data\n",
    "model2.fit(X2_train, y2_train)\n",
    "\n",
    "D=5000\n",
    "\n",
    "# Predict on testing data\n",
    "y_pred = model.predict(X_test)\n",
    "# Make predictions on the testing data\n",
    "new_X2 = np.array([[D,(prediction1*100)]], dtype=object)\n",
    "prediction2 = model2.predict(new_X2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#DATASET 2 - Decision Tree\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# Load data into Pandas DataFrame\n",
    "data3 = pd.read_csv('Radiation_pattern.csv')\n",
    "\n",
    "# Split the dataset into features and target variable\n",
    "X3 = data3[['Radiation']]\n",
    "y3 = data3['Cost']\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "X3_train, X3_test, y3_train, y3_test = train_test_split(X3, y3, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create decision tree regressor model\n",
    "model3 = DecisionTreeRegressor(random_state=42)\n",
    "\n",
    "# Train model on training data\n",
    "model3.fit(X3_train, y3_train)\n",
    "\n",
    "\n",
    "m=prediction2[:,0]\n",
    "if m>0:\n",
    "     m=m/100\n",
    "else:\n",
    "    m=0\n",
    "\n",
    "# Make predictions on the testing data\n",
    "new_X3 = np.reshape(m, (1, -1)) # reshape m to have shape (1, n)\n",
    "prediction3 = model3.predict(new_X3)\n",
    "\n",
    "\n",
    "\n",
    "# Load the data from the CSV file\n",
    "data4 = pd.read_csv('Grid_Price.csv')\n",
    "\n",
    "# Clean the data by removing any missing values\n",
    "data4 = data4.dropna()\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X4 = data4[['Power_Grid']]\n",
    "y4 = data4['Cost']\n",
    "X4_train, X4_test, y4_train, y4_test = train_test_split(X4, y4, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a linear regression model on the training data\n",
    "model4 = LinearRegression()\n",
    "model4.fit(X4_train, y4_train)\n",
    "\n",
    "n=prediction2[:,1]\n",
    "if n<0:\n",
    "    n=0\n",
    "\n",
    "\n",
    "# Make predictions on the testing data\n",
    "new_X4 = np.reshape(n, (1, -1)) # reshape m to have shape (1, n)\n",
    "prediction4 = model4.predict(new_X4)\n",
    "\n",
    "\n",
    "\n",
    "price=prediction3+prediction4\n",
    "print(\"Radiations: \", prediction1)\n",
    "print (\"Demand from user: \", D)\n",
    "print(\"Power taken from solar panel: \" , prediction2[:,0])\n",
    "print(\"Power taken from power grid: \" ,prediction2[:,1])\n",
    "print(\"Cost of solar power used: \", prediction3[0])\n",
    "print(\"Cost of grid power used: \", prediction4[0])\n",
    "print(\"Final Total Price (Predicted): \", price[0])\n",
    "\n",
    "#Calculations to find mathematical values\n",
    "\n",
    "if D>=(prediction1*100):\n",
    "    R=prediction1\n",
    "    g=D-(R*100)\n",
    "else:\n",
    "    g=0\n",
    "    R=D\n",
    "    \n",
    "PS = (480.944*6)/(R)\n",
    "\n",
    "PU1=0\n",
    "\n",
    "if  g >= 1 and g <= 1000:\n",
    "     PU1 = 5.84\n",
    "elif  g > 1000 and g <= 100000:\n",
    "    PU1 = 6.63\n",
    "elif  g > 100000 and g <= 500000:\n",
    "    PU1 = 7.3\n",
    "elif  g > 500000 and g <= 1000000:\n",
    "    PU1 = 7.5\n",
    "\n",
    "PG = g * PU1\n",
    "\n",
    "price2 = PS+PG\n",
    "\n",
    "print(\"Final Total Price (Calculated): \", price2)\n",
    "\n",
    "#Calculating error\n",
    "\n",
    "error= ((abs(price2-price))/price2)*100\n",
    "\n",
    "print(\"Error: \", error[0])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9369d287",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
